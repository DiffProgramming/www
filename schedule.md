---
layout: page
title: Schedule
---

## Schedule 

<br/>
### Session 1 [link to SlidesLive](https://nips.cc/virtual/2021/workshop/21882)
**Chair**:  Maria I. Gorinova (*Twitter*)
<br/>
<table class="schedule">
    <thead>
        <th class="time">BJT</th>
        <th class="time">GMT</th>
        <th class="time">PST</th>
        <th></th>
    </thead>
    <tbody>
    
    <tr>
        <td>
        <p>22:00</p>

        </td>
        <td>
        <p>14:00</p>

        </td>
        <td>
        <p>06:00</p>

        </td>
        <td>
        <p><strong>Short Introduction & Welcome to the Workshop</strong>: Ludger Paehler (<em>Technische Universität München</em>)</p>

        </td>
    </tr>
    
    <tr>
        <td>
        <p>22:05</p>

        </td>
        <td>
        <p>14:05</p>

        </td>
        <td>
        <p>06:05</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Adam Paszke (<em>Google</em>)</p>
<p>Parallel-Friendly Automatic Differentiation in Dex and JAX </p>
</td></tr>
<tr>
        <td>
        <p>22:35</p>

        </td>
        <td>
        <p>14:35</p>

        </td>
        <td>
        <p>06:35</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Yuan Zhou (<em>University of Oxford</em>)</p>
<p>SYMPAIS: SYMbolic Parallel Adaptive Importance Sampling for Probabilistic Program Analysis</p>
</td></tr>
<tr>
        <td>
        <p>23:05</p>

        </td>
        <td>
        <p>15:05</p>

        </td>
        <td>
        <p>07:05</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Uwe Naumann (<em>RWTH Aachen University</em>)</p>
<p>Differentiable Scripting</p>
</td></tr>
<tr>
        <td>
        <p>23:20</p>

        </td>
        <td>
        <p>15:20</p>

        </td>
        <td>
        <p>07:20</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Antonio Stanziola and Simon Arridge (<em>UCL</em>)</p>
<p>A research framework for writing differentiable PDE discretizations in JAX</p>
</td></tr>
</tbody>
</table>

<br/><br/>
### Session 2 [link to SlidesLive](https://nips.cc/virtual/2021/workshop/21882)
**Chair**:  Jan Hückelheim (*Argonne National Laboratory*)
<br/>
<table class="schedule">
    <thead>
        <th class="time">BJT</th>
        <th class="time">GMT</th>
        <th class="time">PST</th>
        <th></th>
    </thead>
    <tbody>
    
    <tr>
        <td>
        <p>23:50</p>

        </td>
        <td>
        <p>15:50</p>

        </td>
        <td>
        <p>07:50</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Frank Noe (<em>Freie Universität Berlin </em>)</p>
<p>Differentiable Programming in Molecular Physics  </p>
</td></tr>
<tr>
        <td>
        <p>00:20</p>

        </td>
        <td>
        <p>16:20</p>

        </td>
        <td>
        <p>08:20</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Keno Fischer (<em>Julia Computing</em>)</p>
<p>Diffractor.jl: High Level, High Performance AD for Julia </p>
</td></tr>
<tr>
        <td>
        <p>00:50</p>

        </td>
        <td>
        <p>16:50</p>

        </td>
        <td>
        <p>08:50</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Patrick Kidger (<em>University of Oxford</em>)</p>
<p>Equinox: neural networks in JAX via callable PyTrees and filtered transformations </p>
</td></tr>
<tr>
        <td>
        <p>01:05</p>

        </td>
        <td>
        <p>17:05</p>

        </td>
        <td>
        <p>09:05</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Deniz Bezgin (<em>Technische Universität München</em>)</p>
<p>A fully-differentiable compressible high-order computational fluid dynamics solver </p>
</td></tr>
</tbody>
</table>

<br/><br/>

### Session 3: Poster Session [link to gather.town](https://eventhosts.gather.town/dn0UpfVPn9AH2SCe/differential-programming)
**Chair**:  William Moses (*MIT*)
<br/>
<table class="schedule">
    <thead>
        <th class="time">BJT</th>
        <th class="time">GMT</th>
        <th class="time">PST</th>
        <th></th>
    </thead>
    <tbody>
    
    <tr>
        <td>
        <p>01:25</p>

        </td>
        <td>
        <p>17:25</p>

        </td>
        <td>
        <p>09:25</p>

        </td>
        <td>
        <p><strong>Poster Session</strong></p>
<ul>
<li>Extended Abstract – Enzyme.jl: Low level auto-differentiation meets high-level language <br/> <em>Valentin Churavy</em></li>
<li>GPU Accelerated Automatic Differentiation with Clad <em>Vassil Vassilev and David Lange</em></li>
<li> Unbiased Reparametrisation Gradient via Smoothing and Diagonalisation <br/><em>Dominik Wagner and Luke Ong</em></li>
<li>Gradients of the Big Bang: Solving the Einstein-Boltzmann Equations with Automatic Differentiation <br/><em>James Sullivan</em></li>
<li>Differentiable Parametric Optimization Approach to Power System Load Modeling <br/><em>Jan Drgona, Andrew August, and Elliott Skomski</em></li>
<li>On automatic differentiation for the Matern covariance <br/><em>Oana Marin and Paul Hovland</em></li>
<li>Neural Differentiable Predictive Control <br/><em>Jan Drgona, Aaron Tuor, and Draguna Vrabie</em></li>
<li>AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming in Julia <br/><em>Frank Schäfer, Mohamed Tarek, Lyndon White, and Chris Rackauckas</em></li>
<li>Aggregated type handling in AD tape implementations <br/><em>Max Sagebaum </em></li>
<li>Backpropagation through Back substitution with a Backslash <br/><em>Ekin Akyürek, Alan Edelman, and Bernie Wang</em></li>
</ul>
</td></tr>
</tbody>
</table>

<br/><br/>
### Session 4 [link to SlidesLive](https://nips.cc/virtual/2021/workshop/21882)
**Chair**:  Assefaw Gebremedhin (*Washington State University*)
<br/>
<table class="schedule">
    <thead>
        <th class="time">BJT</th>
        <th class="time">GMT</th>
        <th class="time">PST</th>
        <th></th>
    </thead>
    <tbody>
    
    <tr>
        <td>
        <p>02:45</p>

        </td>
        <td>
        <p>18:45</p>

        </td>
        <td>
        <p>10:45</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Patrick Heimbach (<em>University of Texas at Austin</em>)</p>
<p>Learning from Data through the Lens of Ocean Models, Surrogates, and their Derivatives</p>
</td></tr>
<tr>
        <td>
        <p>03:15</p>

        </td>
        <td>
        <p>19:15</p>

        </td>
        <td>
        <p>11:15</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Karen Liu (<em>Stanford</em>)</p>
<p>Learnable Physics Models</p>
</td></tr>
<tr>
        <td>
        <p>03:45</p>

        </td>
        <td>
        <p>19:45</p>

        </td>
        <td>
        <p>11:45</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Nacime Bouziani (<em>Imperial College London</em>)</p>
<p>Escaping the abstraction: a foreign function interface for the Unified Form Language [UFL]</p>
</td></tr>
<tr>
        <td>
        <p>04:00</p>

        </td>
        <td>
        <p>20:00</p>

        </td>
        <td>
        <p>12:00</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Alexander Lew (<em>MIT</em>), Mathieu Huot (<em>University of Oxford</em>), and Vikash Mansinghka (<em>MIT</em>)</p>
<p>Towards Denotational Semantics of AD for Higher-Order, Recursive, Probabilistic Languages</p>
</td></tr>
</tbody>
</table>

<br/><br/>
### Session 5 [link to SlidesLive](https://nips.cc/virtual/2021/workshop/21882)
**Chair**:  Sri Hari Krishna Narayanan (*Argonne National Laboratory*)
<br/>
<table class="schedule">
    <thead>
        <th class="time">BJT</th>
        <th class="time">GMT</th>
        <th class="time">PST</th>
        <th></th>
    </thead>
    <tbody>
    
    <tr>
        <td>
        <p>04:30</p>

        </td>
        <td>
        <p>20:30</p>

        </td>
        <td>
        <p>12:30</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Sergey Ovchinnikov (<em>Harvard</em>)</p>
<p>Differentiable Programming for Protein Sequences and Structure</p>
</td></tr>
<tr>
        <td>
        <p>05:00</p>

        </td>
        <td>
        <p>21:00</p>

        </td>
        <td>
        <p>13:00</p>

        </td>
        <td>
        <p><strong>Invited Talk</strong>: Harshitha Menon (<em>Lawrence Livermore National Laboratory</em>)</p>
<p>Approximate High Performance Computing Guided by Automatic Differentiation</p>
</td></tr>
<tr>
        <td>
        <p>05:30</p>

        </td>
        <td>
        <p>21:30</p>

        </td>
        <td>
        <p>13:30</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Gordon Plotkin (<em>University of Edinburgh</em>)</p>
<p>A Complete Axiomatization of Forward Differentiation </p>
</td></tr>
<tr>
        <td>
        <p>05:45</p>

        </td>
        <td>
        <p>21:45</p>

        </td>
        <td>
        <p>13:45</p>

        </td>
        <td>
        <p><strong>Contributed Talk</strong>: Bhupalee Kalita (<em>University of California, Irvine</em>), Ryan Pederson (<em>University of California, Irvine</em>), Li Li (<em>Google</em>), Kieron Burke (<em>University of California, Irvine</em>)</p>
<p>Generalizability of density functionals learned from differentiable programming on weakly correlated spin-polarized systems</p>
</td></tr>
<tr>
        <td>
        <p>06:00</p>

        </td>
        <td>
        <p>22:00</p>

        </td>
        <td>
        <p>14:00</p>

        </td>
        <td>
        <p><strong>Social</strong></p>
        </td>
</tr>
</tbody>
</table>

<br/>
<center> <h3> Sponsors </h3> </center>
<br/>
<center><a href="https://www.google.com/"><img src="/images/google.png" style="height:60px;"></a></center>

<br/>
